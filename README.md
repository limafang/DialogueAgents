# DialogueAgents: A Hybrid Agent-Based Speech Synthesis Framework for Multi-Party Dialogue

Our website is available at [https://icassp.vercel.app/](https://icassp.vercel.app/).

Check our dataset [here](https://drive.google.com/file/d/1iiJ6Nc7RTE2kFVZm_mK4-oBvglLeh7DG/view?usp=sharing).

## ğŸš€ Quickstart
### 1. Clone the Repository
```bash
git clone --recursive https://github.com/FunAudioLLM/DialogueAgents.git
cd DialogueAgents
```
### 2. Download TTS Model
Download the CosyVoice-300M TTS model from [ModelScope](https://www.modelscope.cn/studios/iic/CosyVoice-300M).

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```
### 4. Run the Demo
#### Baseline Mode
Generate dialogue using the baseline mode:

```bash
python demo.py --mode baseline \
    --model_path /path/to/your/tts/model \
    --output_dir test/ \
    --script_path /data/demo.json
```
#### Refine Mode
Before using `refine` and `reflection` mode, configure your OpenAI API key:

```bash
export OPENAI_API_KEY="your_openai_api_key"
export OPENAI_API_BASE_URL="your_openai_base_url"
```
Run the refine mode:

```bash
python demo.py --mode refine \
    --model_path /path/to/your/tts/model \
    --output_dir test/ \
    --script_path /data/demo.json
```
#### Reflection Mode
Use Reflection Mode for iterative, context-aware dialogue generation:

```bash
python demo.py --mode reflection \
    --model_path /path/to/your/tts/model \
    --output_dir reflect/ \
    --script_path /data/demo.json \
    --audio_model_path /path/to/your/audio/llm/path \
    --max_loop 1
```
## ğŸ›  Adding Custom Speakers and Scripts
### 1. Add Speaker Data
Define new speakers in DialogueAgents/data/speaker/speaker.json. Each speaker should have a unique configuration like this:

```json
{
    "æç§€å¨Ÿ": {
        "label": "ä¸­æ–‡å¥³",
        "description": "å’Œè”¼å¯äº²çš„å¥¶å¥¶ï¼Œå–œæ¬¢ç»™å­©å­ä»¬è®²å°æ—¶å€™çš„æ•…äº‹ï¼Œè¯´è¯ç¼“æ…¢ï¼Œå£°éŸ³ç•¥æ²™å“‘ã€‚æ€»æ˜¯å–œæ¬¢å›å¿†è¿‡å»çš„å¾€äº‹ã€‚å¼ å¿ æ˜¯å¥¹çš„å„¿å­ï¼Œæå»ºå›½æ˜¯å¥¹è€ä¼´å„¿",
        "wav": "data/audios/lixiujuan.wav"
    },
    "ç‹å¨Ÿ": {
        "label": "ä¸­æ–‡å¥³",
        "description": "é’å¹´å¥³æ•™å¸ˆï¼Œæ€§æ ¼ç¨³é‡ä¸”æ¸©æŸ”ï¼Œè¯´è¯å¾ˆæœ‰æ¡ç†æ€§ï¼Œç»™äººä¸€ç§å¾ˆäº²å’Œçš„æ„Ÿè§‰ã€‚é€šå¸¸ä¼šå¾ˆè€å¿ƒåœ°è†å¬åˆ«äººçš„é­é‡ï¼Œå¹¶ç»™å‡ºå‹å¥½çš„å»ºè®®ã€‚å¼ å¿—å¼ºæ˜¯å¥¹çš„ä¸ˆå¤«ï¼Œæå°é›ªæ˜¯å¥¹çš„å¥³å„¿ï¼Œåˆ˜ç‡•æ˜¯å¥¹çš„å¥½æœ‹å‹",
        "wav": "data/audios/wangjuan.wav"
    }
}
```
### 2. Add Script Data
Create or update a dialogue script in DialogueAgents/data/script/demo.json. Ensure all speakers are registered in the speaker.json file. Example:

```json
{
    "scripts": [
        {
            "id": 421,
            "topic": "æœ¬åœ°å‰§é™¢æ–°å‰§é¦–æ¼”",
            "conversation": [
                {
                    "speaker": "æç§€å¨Ÿ",
                    "text": "ç‹å¨Ÿï¼Œæœ¬å‘¨äº”æˆ‘ä»¬æœ¬åœ°å‰§é™¢æœ‰ä¸€éƒ¨æ–°å‰§é¦–æ¼”ï¼Œæ˜¯ä¸€éƒ¨å…³äºå†å²çš„å‰§ç›®ï¼Œä½ æ„Ÿå…´è¶£ä¸€èµ·å»è§‚çœ‹å—ï¼Ÿ"
                },
                {
                    "speaker": "ç‹å¨Ÿ",
                    "text": "å¬èµ·æ¥ä¸é”™ï¼Œæˆ‘å¾ˆå–œæ¬¢å†å²å‰§ã€‚å®ƒè®²è¿°ä»€ä¹ˆæ—¶æœŸçš„æ•…äº‹ï¼Ÿ"
                },
                {
                    "speaker": "æç§€å¨Ÿ",
                    "text": "è®²çš„æ˜¯æ–‡è‰ºå¤å…´æ—¶æœŸçš„æ•…äº‹ï¼Œéå¸¸å¼•äººå…¥èƒœã€‚æˆ‘ç›¸ä¿¡ä½ ä¼šå–œæ¬¢çš„ã€‚"
                },
                {
                    "speaker": "ç‹å¨Ÿ",
                    "text": "é‚£å¤ªå¥½äº†ï¼Œæˆ‘ä¸€ç›´å¯¹é‚£ä¸ªæ—¶æœŸå¾ˆæ„Ÿå…´è¶£ã€‚æˆ‘ä»¬å‘¨äº”è§ï¼"
                }
            ]
        }
    ]
}
```